#!/bin/bash
#SBATCH --job-name=s1_s1-7B_gptq-int4
#SBATCH --partition=a100
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --gpus=1
#SBATCH --time=3-00:00:00
#SBATCH --output=logs/s1.1-7B_gptq-int4_output.log
#SBATCH --error=logs/s1.1-7B_gptq-int4_error.log

set -euo pipefail
trap 'echo "âŒ è„šæœ¬å¤±è´¥: è¡Œå· $LINENO, çŠ¶æ€ç  $?"' ERR

echo "ğŸ“Œ SLURM job started on: $(hostname)"
echo "ğŸ“… Date: $(date)"

# âœ… æ¨¡å‹ä¸ä»»åŠ¡è®¾ç½®
MODEL_ID="s1.1-7B-gptq-int4"
MODEL_LOCAL="models/${MODEL_ID}"  # æœ¬åœ°æ¨¡å‹è·¯å¾„
TASK_LIST=("aime24_nofigures" "gpqa_diamond_openai")

DEF_PATH="/mnt/fast/nobackup/scratch4weeks/ly0008/ysh/s1/apptainer.def"
SIF_PATH="/mnt/fast/nobackup/scratch4weeks/ly0008/ysh/s1/s1.sif"
RESULTS_LOCAL="results/${MODEL_ID}"
RESULTS_IN_CONTAINER="/workspace/results/${MODEL_ID}"

mkdir -p "$RESULTS_LOCAL"

# âœ… è¯»å– HF tokenï¼ˆgated dataset å¿…é¡»è¦ï¼‰
HF_TOKEN=$(<.hf_token)
if [ -z "$HF_TOKEN" ]; then
  echo "âŒ .hf_token æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºè¯¥æ–‡ä»¶å¹¶å¡«å…¥ Hugging Face token"
  exit 1
fi

# âœ… æ£€æŸ¥æ¨¡å‹è·¯å¾„
if [ ! -f "${MODEL_LOCAL}/config.json" ]; then
  echo "âŒ æ¨¡å‹è·¯å¾„æ— æ•ˆï¼š${MODEL_LOCAL}/config.json æœªæ‰¾åˆ°"
  exit 1
fi

# âœ… æ£€æŸ¥å¹¶æ„å»ºé•œåƒ
if [ -f "$SIF_PATH" ]; then
  echo "âœ… å®¹å™¨é•œåƒå·²å­˜åœ¨: $SIF_PATHï¼Œè·³è¿‡æ„å»ºã€‚"
else
  echo "ğŸš§ å¼€å§‹æ„å»ºé•œåƒ: $SIF_PATH"
  apptainer build --fakeroot "$SIF_PATH" "$DEF_PATH" || {
    echo "âŒ å®¹å™¨æ„å»ºå¤±è´¥"
    exit 1
  }
fi

# âœ… æ¨ç†ä»»åŠ¡
for k in 512 1024 2048 4096 8192; do
  for task in "${TASK_LIST[@]}"; do
    SUBDIR="${MODEL_ID}_${k}/${task}"
    OUT_DIR="${RESULTS_LOCAL}/${SUBDIR}/${MODEL_ID}"
    echo "ğŸš€ æ¨ç†ä»»åŠ¡ï¼štask=${task}, max_tokens_thinking=${k}"

    apptainer exec --nv \
      --env HF_TOKEN=$HF_TOKEN \
      --bind "$MODEL_LOCAL:/workspace/model" \
      --bind results:/workspace/results \
      "$SIF_PATH" bash -c "
        set -euo pipefail
        huggingface-cli login --token \$HF_TOKEN
        cd /opt/app/s1

        mkdir -p /workspace/results/${SUBDIR}/${MODEL_ID}

        lm_eval \
          --model vllm \
          --model_args pretrained=/workspace/model,dtype=float16,tensor_parallel_size=1 \
          --tasks ${task} \
          --output_path /workspace/results/${SUBDIR}/${MODEL_ID} \
          --log_samples \
          --apply_chat_template \
          --gen_kwargs \"max_gen_toks=32768,max_tokens_thinking=${k}\"
      "

    echo "âœ… å·²å®Œæˆ task=${task}, k=${k}ï¼Œç»“æœä¿å­˜åœ¨ï¼š${OUT_DIR}"
  done
done

echo "ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆã€‚å…¨éƒ¨ç»“æœåœ¨ï¼š$RESULTS_LOCAL/"